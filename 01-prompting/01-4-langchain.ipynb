{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTDgRy0jKDkP"
      },
      "source": [
        "# 01-4: LangChain intro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcrn7QRyQXGj"
      },
      "outputs": [],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkGGSdmtta6s"
      },
      "source": [
        "## 1. LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_dfy6G_aBtY"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlxEmS1CaM5v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = YOOUR_OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY09s9cmZ6nQ"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "# TODO: Implement a basic call to an LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idkq_aVyaceF"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4DKOWjyaRmO"
      },
      "outputs": [],
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = YOUR_HUGGINGFACE_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmtH72oCaU32"
      },
      "outputs": [],
      "source": [
        "from langchain import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uK5TtJPc49I"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement a basic call to an LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O-7dO1htdO4"
      },
      "source": [
        "## 2. Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FDS9IDRapOt"
      },
      "outputs": [],
      "source": [
        "llm(\"Puedo yo tener una conversación con Mozart?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB4W8dM1tPAY"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Question: Puedo yo tener una conversación con Mozart?\n",
        "\n",
        "Let's think step by step.\n",
        "\n",
        "Answer: \"\"\"\n",
        "llm(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU1VyMMvtsCE"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "# TODO: Implement PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zw1KlSeuUOY"
      },
      "source": [
        "## 3. Chains\n",
        "\n",
        "Combine LLMs and Prompts in multi-step workflows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE6n-jbAuOxt"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement a chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp-UlOK0bMVQ"
      },
      "source": [
        "## 4. Agents and Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79JcjhFXwv0J"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOSpaurEb1MR"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement an agent using the wikipedia tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AuQNfhYm48A"
      },
      "source": [
        "## 5. Memory\n",
        "\n",
        "Add State to Chains and Agents.\n",
        "\n",
        "Memory is the concept of persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ujwj29G2cDPN"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI, ConversationChain\n",
        "\n",
        "# TODO: Implement a conversation with memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wMttXM-CuPK"
      },
      "source": [
        "## 6. Document Loaders\n",
        "\n",
        "Combining language models with your own text data is a powerful way to differentiate them. The first step in doing this is to load the data into “documents” - a fancy way of say some pieces of text. This module is aimed at making this easy.\n",
        "\n",
        "https://python.langchain.com/en/latest/modules/indexes/document_loaders.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAiISOcboPKR"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import NotionDirectoryLoader\n",
        "\n",
        "# TODO: Implement a Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_zcj8MLDGfQ"
      },
      "source": [
        "## 7. Indexes\n",
        "\n",
        "Indexes refer to ways to structure documents so that LLMs can best interact with them. This module contains utility functions for working with documents\n",
        "\n",
        "- Embeddings: An embedding is a numerical representation of a piece of information, for example, text, documents, images, audio, etc.\n",
        "- Text Splitters: When you want to deal with long pieces of text, it is necessary to split up that text into chunks.\n",
        "- Vectorstores: Vector databases store and index vector embeddings from NLP models to understand the meaning and context of strings of text, sentences, and whole documents for more accurate and relevant search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLU79cyCozYl"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/hwchase17/langchain/master/docs/modules/state_of_the_union.txt\"\n",
        "res = requests.get(url)\n",
        "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
        "  f.write(res.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGyZXiJZBsov"
      },
      "outputs": [],
      "source": [
        "# Document Loader\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# TODO: Implement a Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OklI0xTvp2KE"
      },
      "outputs": [],
      "source": [
        "# Text Splitter\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# TODO: Implement a a split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skvXSMXHCxyq"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1yCdAhSCi64"
      },
      "outputs": [],
      "source": [
        "# Embeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "# # TODO: Implement Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R3pT55b-uBJ"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7sRydnlC7rb"
      },
      "outputs": [],
      "source": [
        "# Vectorstore: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# TODO: Implement FAISS"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
