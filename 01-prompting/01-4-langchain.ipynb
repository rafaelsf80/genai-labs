{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTDgRy0jKDkP"
      },
      "source": [
        "# 01-4: LangChain intro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcrn7QRyQXGj"
      },
      "outputs": [],
      "source": [
        "#!pip install langchain langchain[openai] langchain-openai langchain-community langgraph langchain-huggingface huggingface_hub --upgrade\n",
        "from importlib.metadata import version\n",
        "print(f\"langchain {version('langchain')}, langchain-openai {version('langchain-openai')}, langchain-huggingface {version('langchain-huggingface')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkGGSdmtta6s"
      },
      "source": [
        "## 1. LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlxEmS1CaM5v"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import getpass\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass() # <--- ENTER YOUR OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY09s9cmZ6nQ"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# TODO: Implement a basic call to an LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O-7dO1htdO4"
      },
      "source": [
        "## 2. Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU1VyMMvtsCE"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# TODO: Implement ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB4W8dM1tPAY"
      },
      "outputs": [],
      "source": [
        "prompt = prompt_template.invoke({\"language\": \"spanish\", \"text\": \"hi!\"})\n",
        "\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FDS9IDRapOt"
      },
      "outputs": [],
      "source": [
        "prompt.to_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = model.invoke(prompt)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zw1KlSeuUOY"
      },
      "source": [
        "## 3. Chains\n",
        "\n",
        "Combine LLMs and Prompts in multi-step workflows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE6n-jbAuOxt"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement a chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp-UlOK0bMVQ"
      },
      "source": [
        "## 4. Agents and Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79JcjhFXwv0J"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOSpaurEb1MR"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement an agent using the wikipedia tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AuQNfhYm48A"
      },
      "source": [
        "## 5. Memory\n",
        "\n",
        "Add State to Chains and Agents.\n",
        "\n",
        "Memory is the concept of persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ujwj29G2cDPN"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(\n",
        "            content=\"You are a helpful assistant. Answer all questions to the best of your ability.\"\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | model\n",
        "\n",
        "ai_msg = chain.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(\n",
        "                content=\"Translate from English to French: I love programming.\"\n",
        "            ),\n",
        "            AIMessage(content=\"J'adore la programmation.\"),\n",
        "            HumanMessage(content=\"What did you just say?\"),\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "print(ai_msg.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wMttXM-CuPK"
      },
      "source": [
        "## 6. Document Loaders\n",
        "\n",
        "Combining language models with your own text data is a powerful way to differentiate them. The first step in doing this is to load the data into “documents” - a fancy way of say some pieces of text. This module is aimed at making this easy.\n",
        "\n",
        "https://python.langchain.com/en/latest/modules/indexes/document_loaders.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAiISOcboPKR"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import NotionDirectoryLoader\n",
        "\n",
        "# TODO: Implement a Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_zcj8MLDGfQ"
      },
      "source": [
        "## 7. Indexes\n",
        "\n",
        "Indexes refer to ways to structure documents so that LLMs can best interact with them. This module contains utility functions for working with documents\n",
        "\n",
        "- Embeddings: An embedding is a numerical representation of a piece of information, for example, text, documents, images, audio, etc.\n",
        "- Text Splitters: When you want to deal with long pieces of text, it is necessary to split up that text into chunks.\n",
        "- Vectorstores: Vector databases store and index vector embeddings from NLP models to understand the meaning and context of strings of text, sentences, and whole documents for more accurate and relevant search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLU79cyCozYl"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://gist.githubusercontent.com/jsdario/6d6c69398cb0c73111e49f1218960f79/raw/8d4fc4548d437e2a7203a5aeeace5477f598827d/el_quijote.txt\"\n",
        "res = requests.get(url)\n",
        "with open(\"el_quijote.txt\", \"w\") as f:\n",
        "  f.write(res.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGyZXiJZBsov"
      },
      "outputs": [],
      "source": [
        "# Document Loader\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# TODO: Implement a Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OklI0xTvp2KE"
      },
      "outputs": [],
      "source": [
        "# Text Splitter\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# TODO: Implement a split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skvXSMXHCxyq"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1yCdAhSCi64"
      },
      "outputs": [],
      "source": [
        "# Embeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "# TODO: Implement Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R3pT55b-uBJ"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7sRydnlC7rb"
      },
      "outputs": [],
      "source": [
        "# Vectorstore: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# TODO: Implement FAISS"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
