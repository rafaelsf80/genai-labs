{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A1Cp1VT6xkl"
      },
      "source": [
        "# 03-6: Ray tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DaGhQ-I6xkp",
        "outputId": "53f5e999-48ee-4d56-fb6d-46327e64de90"
      },
      "outputs": [],
      "source": [
        "# This install is MANDATORY for Google Colab\n",
        "!pip uninstall -y -q pyarrow\n",
        "!pip install -q -U ray[tune]\n",
        "!pip install -q ray[debug]\n",
        "\n",
        "# A hack to force the runtime to restart, needed to include the above dependencies.\n",
        "print(\"Done installing! Restarting via forced crash (this is not an issue).\")\n",
        "import os\n",
        "os._exit(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihZ3z-JC6xkr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "import tensorflow as tf\n",
        "try:\n",
        "    tf.get_logger().setLevel('INFO')\n",
        "except Exception as exc:\n",
        "    print(exc)\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import ray\n",
        "from ray import tune\n",
        "from ray.tune.examples.utils import get_iris_data\n",
        "\n",
        "import inspect\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pro3MwEo6xks"
      },
      "source": [
        "## Visualize your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "usb0q0BC6xkt",
        "outputId": "4f9d4192-6c26-4511-e36e-20b829dbe2ee"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "true_data = iris['data']\n",
        "true_label = iris['target']\n",
        "names = iris['target_names']\n",
        "feature_names = iris['feature_names']\n",
        "\n",
        "def plot_data(X, y):\n",
        "    # Visualize the data sets\n",
        "    plt.figure(figsize=(16, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for target, target_name in enumerate(names):\n",
        "        X_plot = X[y == target]\n",
        "        plt.plot(X_plot[:, 0], X_plot[:, 1], linestyle='none', marker='o', label=target_name)\n",
        "    plt.xlabel(feature_names[0])\n",
        "    plt.ylabel(feature_names[1])\n",
        "    plt.axis('equal')\n",
        "    plt.legend();\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for target, target_name in enumerate(names):\n",
        "        X_plot = X[y == target]\n",
        "        plt.plot(X_plot[:, 2], X_plot[:, 3], linestyle='none', marker='o', label=target_name)\n",
        "    plt.xlabel(feature_names[2])\n",
        "    plt.ylabel(feature_names[3])\n",
        "    plt.axis('equal')\n",
        "    plt.legend();\n",
        "\n",
        "plot_data(true_data, true_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFGeLxCM6xkt"
      },
      "source": [
        "## Creating a model training procedure (using Keras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnYfLuO16xku"
      },
      "source": [
        "Now, let's define a function that will take in some hyperparameters and return a model that we can then use to train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzl7kEW16xku"
      },
      "outputs": [],
      "source": [
        "def create_model(learning_rate, dense_1, dense_2):\n",
        "    assert learning_rate > 0 and dense_1 > 0 and dense_2 > 0, \"Did you set the right configuration?\"\n",
        "    model = Sequential()\n",
        "    model.add(Dense(int(dense_1), input_shape=(4,), activation='relu', name='fc1'))\n",
        "    model.add(Dense(int(dense_2), activation='relu', name='fc2'))\n",
        "    model.add(Dense(3, activation='softmax', name='output'))\n",
        "    optimizer = SGD(lr=learning_rate)\n",
        "    model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3um7kV06xku"
      },
      "source": [
        "Below is a function that trains the model using the ``create_model`` function and returns the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46S7fi-76xku"
      },
      "outputs": [],
      "source": [
        "def train_on_iris():\n",
        "    train_x, train_y, test_x, test_y = get_iris_data()\n",
        "    model = create_model(learning_rate=0.1, dense_1=2, dense_2=2)\n",
        "    # This saves the top model. `accuracy` is only available in TF2.0.\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        \"model.h5\", monitor='accuracy', save_best_only=True, save_freq=2)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        train_x, train_y,\n",
        "        validation_data=(test_x, test_y),\n",
        "        verbose=0, batch_size=10, epochs=20, callbacks=[checkpoint_callback])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f6QCtP26xku"
      },
      "source": [
        "Let's quickly train the model on the dataset. The accuracy should be quite low."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQCfc9vy6xkv",
        "outputId": "c4ed82b9-e850-4841-f8ec-2180950f1cd9"
      },
      "outputs": [],
      "source": [
        "original_model = train_on_iris()  # This trains the model and returns it.\n",
        "train_x, train_y, test_x, test_y = get_iris_data()\n",
        "original_loss, original_accuracy = original_model.evaluate(test_x, test_y, verbose=0)\n",
        "print(\"Loss is {:0.4f}\".format(original_loss))\n",
        "print(\"Accuracy is {:0.4f}\".format(original_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o45SHn9j6xkv"
      },
      "source": [
        "## Integrate with Tune\n",
        "\n",
        "Now, let's use Tune to optimize a model that learns to classify Iris. This will happen in two parts - **modifying** the training function to support Tune, and then **configuring** Tune.\n",
        "\n",
        "Let's first define a callback function to report intermediate training progress back to Tune."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK6B0kVu6xkv"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "from ray import tune, train\n",
        "\n",
        "\n",
        "class TuneReporterCallback(keras.callbacks.Callback):\n",
        "    \"\"\"Tune Callback for Keras.\n",
        "\n",
        "    The callback is invoked every epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, logs={}):\n",
        "        self.iteration = 0\n",
        "        super(TuneReporterCallback, self).__init__()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.iteration += 1\n",
        "        #tune.report(keras_info=logs, mean_accuracy=logs.get(\"accuracy\"), mean_loss=logs.get(\"loss\"))\n",
        "        train.report({\"keras_info\": logs, \"mean_accuracy\": logs.get(\"accuracy\"), \"mean_loss\": logs.get(\"loss\")})  # This sends the score to Tune.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4Z-6Clu6xkv"
      },
      "source": [
        "### Modifying the Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J_AuDmO6xkv"
      },
      "outputs": [],
      "source": [
        "def tune_iris(config):\n",
        "    train_x, train_y, test_x, test_y = get_iris_data()\n",
        "    model = create_model(learning_rate=config[\"lr\"], dense_1=config[\"dense_1\"], dense_2=config[\"dense_2\"])\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        \"model.h5\", monitor='loss', save_best_only=True, save_freq=2)\n",
        "\n",
        "    # Enable Tune to make intermediate decisions by using a Tune Callback hook. This is Keras specific.\n",
        "    callbacks = [checkpoint_callback, TuneReporterCallback()]\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        train_x, train_y,\n",
        "        validation_data=(test_x, test_y),\n",
        "        verbose=0,\n",
        "        batch_size=10,\n",
        "        epochs=20,\n",
        "        callbacks=callbacks)\n",
        "\n",
        "assert len(inspect.getargspec(tune_iris).args) == 1, \"The `tune_iris` function needs to take in the arg `config`.\"\n",
        "\n",
        "# print(\"Test-running to make sure this function will run correctly.\")\n",
        "# tune.track.init()  # For testing purposes only.\n",
        "# tune_iris({\"lr\": 0.1, \"dense_1\": 4, \"dense_2\": 4})\n",
        "# print(\"Success!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI9ZGm8M6xkw"
      },
      "source": [
        "# Launch a Tune hyperparameter search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btN_RK9y6xkw",
        "outputId": "dd675fd1-9fe5-4d39-f47d-fb9ef9e5e1f5",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# This seeds the hyperparameter sampling.\n",
        "import numpy as np; np.random.seed(5)\n",
        "hyperparameter_space = {\n",
        "    \"lr\": tune.loguniform(0.001, 0.1),\n",
        "    \"dense_1\": tune.uniform(2, 128),\n",
        "    \"dense_2\": tune.uniform(2, 128),\n",
        "}\n",
        "num_samples = 20  # TODO: Fill me out.\n",
        "\n",
        "####################################################################################################\n",
        "################ This is just a validation function for tutorial purposes only. ####################\n",
        "HP_KEYS = [\"lr\", \"dense_1\", \"dense_2\"]\n",
        "assert all(key in hyperparameter_space for key in HP_KEYS), (\n",
        "    \"The hyperparameter space is not fully designated. It must include all of {}\".format(HP_KEYS))\n",
        "######################################################################################################\n",
        "\n",
        "ray.shutdown()  # Restart Ray defensively in case the ray connection is lost.\n",
        "ray.init(log_to_driver=False)\n",
        "# We clean out the logs before running for a clean visualization later.\n",
        "! rm -rf ~/ray_results/tune_iris\n",
        "\n",
        "analysis = tune.run(\n",
        "    tune_iris,\n",
        "    verbose=1,\n",
        "    config=hyperparameter_space,\n",
        "    num_samples=num_samples)\n",
        "\n",
        "assert len(analysis.trials) == 20, \"Did you set the correct number of samples?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvjOPjq26xkw"
      },
      "source": [
        "## Analyze the best tuned model\n",
        "\n",
        "Let's compare the real labels with the classified labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "1MrswZlT6xkw",
        "outputId": "19d46aec-739c-45ba-9c9d-9ae7e5d87463",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "_, _, test_data, test_labels = get_iris_data()\n",
        "plot_data(test_data, test_labels.argmax(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "CwMtH0nQ6xkw",
        "outputId": "b5e32fb7-72bb-4a3f-ed5b-44b6ef66a0b9"
      },
      "outputs": [],
      "source": [
        "# Obtain the directory where the best model is saved.\n",
        "print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
        "    [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
        "print(\"=\" * 10)\n",
        "\n",
        "logdir = analysis.get_best_trial(\"keras_info/val_loss\", mode=\"min\")\n",
        "print(logdir)\n",
        "# We saved the model as `model.h5` in the logdir of the trial.\n",
        "from tensorflow.keras.models import load_model\n",
        "tuned_model = load_model(\"./model.h5\")\n",
        "\n",
        "tuned_loss, tuned_accuracy = tuned_model.evaluate(test_data, test_labels, verbose=0)\n",
        "print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
        "print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
        "print(\"The original un-tuned model had an accuracy of {:0.4f}\".format(original_accuracy))\n",
        "predicted_label = tuned_model.predict(test_data)\n",
        "plot_data(test_data, predicted_label.argmax(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lymteSyK6xkw"
      },
      "source": [
        "We can compare the performance of the best model by visualizing predictions compared to the ground truth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "UQ3zc-gh6xkx",
        "outputId": "c263e340-91bc-411b-b373-25076b100846"
      },
      "outputs": [],
      "source": [
        "def plot_comparison(X, y):\n",
        "    # Visualize the data sets\n",
        "    plt.figure(figsize=(16, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for target, target_name in enumerate([\"Incorrect\", \"Correct\"]):\n",
        "        X_plot = X[y == target]\n",
        "        plt.plot(X_plot[:, 0], X_plot[:, 1], linestyle='none', marker='o', label=target_name)\n",
        "    plt.xlabel(feature_names[0])\n",
        "    plt.ylabel(feature_names[1])\n",
        "    plt.axis('equal')\n",
        "    plt.legend();\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for target, target_name in enumerate([\"Incorrect\", \"Correct\"]):\n",
        "        X_plot = X[y == target]\n",
        "        plt.plot(X_plot[:, 2], X_plot[:, 3], linestyle='none', marker='o', label=target_name)\n",
        "    plt.xlabel(feature_names[2])\n",
        "    plt.ylabel(feature_names[3])\n",
        "    plt.axis('equal')\n",
        "    plt.legend();\n",
        "\n",
        "plot_comparison(test_data, test_labels.argmax(1) == predicted_label.argmax(1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
