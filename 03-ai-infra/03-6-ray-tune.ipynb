{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A1Cp1VT6xkl"
      },
      "source": [
        "# 03-6: Ray tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DaGhQ-I6xkp",
        "outputId": "53f5e999-48ee-4d56-fb6d-46327e64de90"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq \"ray[tune]\" torch torchvision\n",
        "\n",
        "# Colab only:\n",
        "import os\n",
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    os._exit(0)() # Restart Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihZ3z-JC6xkr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from filelock import FileLock\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "from ray import train, tune\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pro3MwEo6xks"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "usb0q0BC6xkt",
        "outputId": "4f9d4192-6c26-4511-e36e-20b829dbe2ee"
      },
      "outputs": [],
      "source": [
        "def load_data(data_dir=\"./data\"):\n",
        "    \"\"\"Create dataloaders for normalized CIFAR10 training/test subsets.\"\"\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    # We add FileLock here because multiple workers will want to\n",
        "    # download data, and this may cause overwrites since\n",
        "    # DataLoader is not threadsafe.\n",
        "    with FileLock(os.path.expanduser(\"~/.data.lock\")):\n",
        "        trainset = torchvision.datasets.CIFAR10(\n",
        "            root=data_dir, train=True, download=True, transform=transform)\n",
        "\n",
        "        testset = torchvision.datasets.CIFAR10(\n",
        "            root=data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    return trainset, testset\n",
        "\n",
        "def create_dataloaders(trainset, batch_size, num_workers=8):\n",
        "    \"\"\"Create train/val splits and dataloaders.\"\"\"\n",
        "    train_size = int(len(trainset) * 0.8)\n",
        "    train_subset, val_subset = random_split(\n",
        "        trainset, [train_size, len(trainset) - train_size])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_subset,\n",
        "        batch_size=batch_size, \n",
        "        shuffle=True,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False, \n",
        "        num_workers=num_workers\n",
        "    )\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_test_data():\n",
        "    # Load fake data for running a quick smoke-test.\n",
        "    trainset = torchvision.datasets.FakeData(\n",
        "        128, (3, 32, 32), num_classes=10, transform=transforms.ToTensor()\n",
        "    )\n",
        "    testset = torchvision.datasets.FakeData(\n",
        "        16, (3, 32, 32), num_classes=10, transform=transforms.ToTensor()\n",
        "    )\n",
        "    return trainset, testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFGeLxCM6xkt"
      },
      "source": [
        "## Arquitectura Conv2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzl7kEW16xku"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, l1=120, l2=84):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
        "        self.fc2 = nn.Linear(l1, l2)\n",
        "        self.fc3 = nn.Linear(l2, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46S7fi-76xku"
      },
      "outputs": [],
      "source": [
        "def train_cifar(config):\n",
        "    net = Net(config[\"l1\"], config[\"l2\"])\n",
        "    device = config[\"device\"]\n",
        "    if device == \"cuda\":\n",
        "        net = nn.DataParallel(net)\n",
        "    net.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9, weight_decay=5e-5)\n",
        "\n",
        "    # Load existing checkpoint through `get_checkpoint()` API.\n",
        "    if tune.get_checkpoint():\n",
        "        loaded_checkpoint = tune.get_checkpoint()\n",
        "        with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
        "            model_state, optimizer_state = torch.load(\n",
        "                os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\")\n",
        "            )\n",
        "            net.load_state_dict(model_state)\n",
        "            optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "    # Data setup\n",
        "    if config[\"smoke_test\"]:\n",
        "        trainset, _ = load_test_data()\n",
        "    else:\n",
        "        trainset, _ = load_data()\n",
        "    train_loader, val_loader = create_dataloaders(\n",
        "        trainset, \n",
        "        config[\"batch_size\"],\n",
        "        num_workers=0 if config[\"smoke_test\"] else 8\n",
        "    )\n",
        "\n",
        "    for epoch in range(config[\"max_num_epochs\"]):  # loop over the dataset multiple times\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            optimizer.zero_grad()  # reset gradients\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        net.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = net(inputs)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # Report metrics\n",
        "        metrics = {\n",
        "            \"loss\": val_loss / len(val_loader),\n",
        "            \"accuracy\": correct / total,\n",
        "        }\n",
        "\n",
        "        # Here we save a checkpoint. It is automatically registered with\n",
        "        # Ray Tune and will potentially be accessed through in ``get_checkpoint()``\n",
        "        # in future iterations.\n",
        "        # Note to save a file-like checkpoint, you still need to put it under a directory\n",
        "        # to construct a checkpoint.\n",
        "        with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
        "            path = os.path.join(temp_checkpoint_dir, \"checkpoint.pt\")\n",
        "            torch.save(\n",
        "                (net.state_dict(), optimizer.state_dict()), path\n",
        "            )\n",
        "            checkpoint = tune.Checkpoint.from_directory(temp_checkpoint_dir)\n",
        "            tune.report(metrics, checkpoint=checkpoint)\n",
        "    print(\"Finished Training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQCfc9vy6xkv",
        "outputId": "c4ed82b9-e850-4841-f8ec-2180950f1cd9"
      },
      "outputs": [],
      "source": [
        "def test_best_model(best_result, smoke_test=False):\n",
        "    best_trained_model = Net(best_result.config[\"l1\"], best_result.config[\"l2\"])\n",
        "    device = best_result.config[\"device\"]\n",
        "    if device == \"cuda\":\n",
        "        best_trained_model = nn.DataParallel(best_trained_model)\n",
        "    best_trained_model.to(device)\n",
        "\n",
        "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
        "\n",
        "    model_state, _optimizer_state = torch.load(checkpoint_path)\n",
        "    best_trained_model.load_state_dict(model_state)\n",
        "\n",
        "    if smoke_test:\n",
        "        _trainset, testset = load_test_data()\n",
        "    else:\n",
        "        _trainset, testset = load_data()\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=4, shuffle=False, num_workers=2\n",
        "    )\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = best_trained_model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    print(f\"Best trial test set accuracy: {correct / total}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set this to True for a smoke test that runs with a small synthetic dataset.\n",
        "SMOKE_TEST = True\n",
        "\n",
        "config = {\n",
        "    \"l1\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
        "    \"l2\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
        "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
        "    \"batch_size\": tune.choice([2, 4, 8, 16]),\n",
        "    \"smoke_test\": SMOKE_TEST,\n",
        "    \"num_trials\": 10 if not SMOKE_TEST else 2,\n",
        "    \"max_num_epochs\": 10 if not SMOKE_TEST else 2,\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main(config, gpus_per_trial=1):\n",
        "    scheduler = ASHAScheduler(\n",
        "        time_attr=\"training_iteration\",\n",
        "        max_t=config[\"max_num_epochs\"],\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "    \n",
        "    tuner = tune.Tuner(\n",
        "        tune.with_resources(\n",
        "            tune.with_parameters(train_cifar),\n",
        "            resources={\"cpu\": 2, \"gpu\": gpus_per_trial}\n",
        "        ),\n",
        "        tune_config=tune.TuneConfig(\n",
        "            metric=\"loss\",\n",
        "            mode=\"min\",\n",
        "            scheduler=scheduler,\n",
        "            num_samples=config[\"num_trials\"],\n",
        "        ),\n",
        "        param_space=config,\n",
        "    )\n",
        "    results = tuner.fit()\n",
        "    \n",
        "    best_result = results.get_best_result(\"loss\", \"min\")\n",
        "\n",
        "    print(f\"Best trial config: {best_result.config}\")\n",
        "    print(f\"Best trial final validation loss: {best_result.metrics['loss']}\")\n",
        "    print(f\"Best trial final validation accuracy: {best_result.metrics['accuracy']}\")\n",
        "\n",
        "    test_best_model(best_result, smoke_test=config[\"smoke_test\"])\n",
        "\n",
        "main(config, gpus_per_trial=1 if torch.cuda.is_available() else 0)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
