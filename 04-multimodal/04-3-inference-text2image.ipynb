{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04-3: Inference text-to-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dall-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai invisible_watermark transformers accelerate safetensors diffusers controlnet_aux==0.0.7 xformers mediapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load your API key from an environment variable or secret management service\n",
    "openai_api_key = YOUR_OPEN_API_KEY # <--- CHANGE THIS !!\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "response = client.images.generate(\n",
    "  model=\"dall-e-3\",\n",
    "  prompt=\"a photo of a dog holding up a sign that says 'I love MADRID'\", #a white siamese cat\",\n",
    "  size=\"1024x1024\",\n",
    "  quality=\"standard\",\n",
    "  n=1,\n",
    ")\n",
    "\n",
    "# Each image can be returned as either a URL or Base64 data, using the response_format parameter. URLs will expire after an hour.\n",
    "# https://beta.openai.com/docs/guides/images/usage\n",
    "image_url = response.data[0].url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Diffusion 1.5 with DDIM scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "\n",
    "ddim = DDIMScheduler.from_config(\"runwayml/stable-diffusion-v1-5\", subfolder=\"scheduler\")\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", scheduler=ddim)\n",
    "\n",
    "image = pipeline(\"An astronaut riding a horse.\").images[0]\n",
    "\n",
    "image.save(\"astronaut_riding_a_horse.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Diffusion XL 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLImg2ImgPipeline, DiffusionPipeline, KDPM2AncestralDiscreteScheduler, StableDiffusionXLPipeline, AutoencoderKL\n",
    "import gc\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "v_autoencoder = \"madebyollin/sdxl-vae-fp16-fix\" # fix vae for run in fp16 precision without generating NaNs\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(v_autoencoder, torch_dtype=torch.float16)\n",
    "\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    model_base,\n",
    "    vae=vae,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    variant=\"fp16\",\n",
    "    add_watermarker=False, # no watermarker\n",
    "    )\n",
    "\n",
    "pipe.safety_checker = None\n",
    "\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_refiner = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
    "\n",
    "pipe_refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "    model_refiner,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    variant=\"fp16\",\n",
    "    add_watermarker=False, # no watermarker\n",
    "    )\n",
    "\n",
    "#pipe_refiner.to(\"cuda\")\n",
    "pipe_refiner.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation with the base model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Optional) Change the scheduler\n",
    "pipe.scheduler = KDPM2AncestralDiscreteScheduler.from_config(\n",
    "pipe.scheduler.config, use_karras_sigmas=True\n",
    ")\n",
    "#generator = torch.Generator().manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max 77 tokens in prompt\n",
    "prompt = \"full body,Cyber goth Geisha in the rain in a  tokyo future  city city wide, Pretty Face, Beautiful eyes, Anime, Portrait, Dark Aesthetic, Neon sunset blade runner background, Concept Art, Digital Art, Anime Art, unreal engine, greg rutkowski, loish, rhads, beeple, makoto shinkai, haruyo morita and lois\"\n",
    "prompt2 = \"Cyber goth Geisha in the rain, stylized cyberpunk black tokyo market, indoor in the style of blade runner, stands illuminated by greens neon lights, crowded with cyborgs photorealistic background, 3 5 mm, grainy ruined film, dark color scheme, ray tracing, unreal engine, 4 k long shot\"\n",
    "negative_prompt = ''\n",
    "negative_prompt2 = ''\n",
    "\n",
    "image_base = pipe(\n",
    "    prompt=prompt,\n",
    "    prompt_2=prompt2,\n",
    "    negative_prompt=negative_prompt,\n",
    "    negative_prompt_2=negative_prompt2,\n",
    "    guidance_scale=9.0,\n",
    "    num_inference_steps=50,\n",
    "    ).images[0]\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the refiner with the generated image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_refiner = pipe_refiner(\n",
    "    prompt=prompt,\n",
    "    prompt_2=prompt2,\n",
    "    negative_prompt=negative_prompt,\n",
    "    negative_prompt_2=negative_prompt2,\n",
    "    image=image_base,\n",
    "    num_inference_steps=50,\n",
    "    strength=0.3,\n",
    "    ).images[0]\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_refiner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
